#
# Copyright (C) 2022 Apple Inc. All rights reserved.
#

import os
import joblib

import numpy as np
import torch
from tqdm import tqdm
import PIL
import scipy

from . import colmap_helper
from .geometry import pcd_projector
from .cameras import captures as captures_module, contents
from .scenes import scene as scene_module
from .utils import ray_utils
from .smpl import SMPL


def read_obj(path):
    vert = []
    uvs = []
    faces = []
    with open(path) as f:
        for line in f:
            line = line.rstrip('\n')
            if line[:2] == 'v ':
                v = line[2:].split()
                v = [float(i) for i in v]
                vert.append(np.array(v))
            elif line[:3] == 'vt ':
                uv = line[3:].split()
                uv = [float(i) for i in uv]
                uvs.append(np.array(uv))
            elif line[:2] == 'f ':
                f = line[2:].split()
                fv = [int(i.split('/')[0]) for i in f]
                ft = [int(i.split('/')[1]) for i in f]
                faces.append(np.array(fv + ft))

    vert = np.array(vert)
    uvs = np.array(uvs)
    faces = np.array(faces) - 1
    return vert, uvs, faces


class NeuManCapture(captures_module.RigRGBDPinholeCapture):
    def __init__(self, image_path, depth_path, mask_path, pinhole_cam, cam_pose, view_id, cam_id, mono_depth_path=None, keypoints_path=None, densepose_path=None):
        captures_module.RigRGBDPinholeCapture.__init__(self, image_path, depth_path, pinhole_cam, cam_pose, view_id, cam_id)
        self.captured_mask = contents.CapturedImage(
            mask_path
        )
        if mono_depth_path is not None:
            self.captured_mono_depth = contents.CapturedDepth(
                mono_depth_path
            )
            self.captured_mono_depth.dataset = 'mono'
        else:
            self.captured_mono_depth = None

        if keypoints_path is not None:
            self.keypoints = np.load(keypoints_path)
        else:
            self.keypoints = None

        if densepose_path is not None:
            self.densepose = np.load(densepose_path)
        else:
            self.densepose = None

        self._fused_depth_map = None

    def read_image_to_ram(self):
        if self.captured_mono_depth is None:
            return self.captured_image.read_image_to_ram() + self.captured_mask.read_image_to_ram()
        else:
            return self.captured_image.read_image_to_ram() + self.captured_mask.read_image_to_ram() + self.captured_mono_depth.read_depth_to_ram()

    @property
    def mask(self):
        _mask = self.captured_mask.image.copy()
        if _mask.max() == 255:
            # Detectron2 mask
            _mask[_mask == 255] = 1
            _mask = 1 - _mask
        else:
            raise ValueError
        assert _mask.sum() > 0
        assert _mask.shape[0:2] == self.pinhole_cam.shape, f'mask does not match with camera model: mask shape: {_mask.shape}, pinhole camera: {self.pinhole_cam}'
        return _mask

    @property
    def binary_mask(self):
        _mask = self.mask.copy()
        _mask[_mask > 0] = 1
        return _mask

    @property
    def mono_depth_map(self):
        return self.captured_mono_depth.depth_map

    @property
    def fused_depth_map(self):
        if self._fused_depth_map is None:
            valid_mask = (self.depth_map > 0) & (self.mask == 0)
            x = self.mono_depth_map[valid_mask]
            y = self.depth_map[valid_mask]
            res = scipy.stats.linregress(x, y)
            self._fused_depth_map = self.depth_map.copy()
            self._fused_depth_map[~valid_mask] = self.mono_depth_map[~valid_mask] * res.slope + res.intercept
        return self._fused_depth_map


class ResizedNeuManCapture(captures_module.ResizedRigRGBDPinholeCapture):
    def __init__(self, image_path, depth_path, mask_path, pinhole_cam, cam_pose, tgt_size, view_id, cam_id, mono_depth_path=None, keypoints_path=None, densepose_path=None):
        captures_module.ResizedRigRGBDPinholeCapture.__init__(self, image_path, depth_path, pinhole_cam, cam_pose, tgt_size, view_id, cam_id)
        '''
        Note: we pass in the original intrinsic and distortion matrix, NOT the resized intrinsic
        '''
        self.captured_mask = contents.ResizedCapturedImage(
            mask_path,
            tgt_size,
            sampling=PIL.Image.NEAREST
        )
        if mono_depth_path is not None:
            self.captured_mono_depth = contents.ResizedCapturedDepth(
                mono_depth_path,
                tgt_size=tgt_size
            )
            self.captured_mono_depth.dataset = 'mono'
        else:
            self.captured_mono_depth = None
        if keypoints_path is not None:
            # raise NotImplementedError
            self.keypoints = None
        else:
            self.keypoints = None
        if densepose_path is not None:
            # raise NotImplementedError
            self.densepose = None
        else:
            self.densepose = None

    def read_image_to_ram(self):
        if self.captured_mono_depth is None:
            return self.captured_image.read_image_to_ram() + self.captured_mask.read_image_to_ram()
        else:
            return self.captured_image.read_image_to_ram() + self.captured_mask.read_image_to_ram() + self.captured_mono_depth.read_depth_to_ram()

    @property
    def mask(self):
        _mask = self.captured_mask.image.copy()
        if _mask.max() == 255:
            # Detectron2 mask
            _mask[_mask == 255] = 1
            _mask = 1 - _mask
        else:
            raise ValueError
        assert _mask.sum() > 0
        assert _mask.shape[0:2] == self.pinhole_cam.shape, f'mask does not match with camera model: mask shape: {_mask.shape}, pinhole camera: {self.pinhole_cam}'
        return _mask

    @property
    def binary_mask(self):
        _mask = self.mask.copy()
        _mask[_mask > 0] = 1
        return _mask

    @property
    def mono_depth_map(self):
        return self.captured_mono_depth.depth_map


def create_split_files(scene_dir):
    # 10% as test set
    # 10% as validation set
    # 80% as training set
    dummy_scene = NeuManReader.read_scene(scene_dir)
    scene_length = len(dummy_scene.captures)
    num_val = scene_length // 5
    length = int(1 / (num_val) * scene_length)
    offset = length // 2
    val_list = list(range(scene_length))[offset::length]
    train_list = list(set(range(scene_length)) - set(val_list))
    test_list = val_list[:len(val_list) // 2]
    val_list = val_list[len(val_list) // 2:]
    assert len(train_list) > 0
    assert len(test_list) > 0
    assert len(val_list) > 0
    splits = []
    for l, split in zip([train_list, val_list, test_list], ['train', 'val', 'test']):
        output = []
        save_path = os.path.join(scene_dir, f'{split}_split.txt')
        for i, cap in enumerate(dummy_scene.captures):
            if i in l:
                output.append(os.path.basename(cap.image_path))
        with open(save_path, 'w') as f:
            for item in output:
                f.write("%s\n" % item)
        splits.append(save_path)
    return splits


def read_text(txt_file):
    '''
    read the split file to a list
    '''
    assert os.path.isfile(txt_file)
    items = []
    with open(txt_file, "r") as fid:
        while True:
            line = fid.readline()
            if not line:
                break
            items.append(line.strip())
    return items


class NeuManReader():
    def __init__(self):
        pass

    #     | å‚æ•°å                 | ç±»å‹            | è¯´æ˜                                                 |
    # | ------------------- | ------------- | -------------------------------------------------- |
    # | `scene_dir`         | str           | åœºæ™¯ä¸»ç›®å½•ï¼ˆåŒ…å« `images/`, `sparse/`, `depth_maps/` ç­‰å­ç›®å½•ï¼‰ |
    # | `tgt_size`          | tuple or None | å›¾åƒç›®æ ‡å°ºå¯¸ï¼Œç”¨äº resize å›¾åƒ                                |
    # | `normalize`         | bool          | æ˜¯å¦å¯¹åœºæ™¯è¿›è¡Œå½’ä¸€åŒ–ï¼ˆè°ƒæ•´ç›¸æœºåæ ‡ç¼©æ”¾ï¼‰                               |
    # | `bkg_range_scale`   | float         | èƒŒæ™¯åŒºåŸŸçš„ near/far èŒƒå›´ç¼©æ”¾å› å­                              |
    # | `human_range_scale` | float         | äººä½“åŒºåŸŸçš„ near/far èŒƒå›´ç¼©æ”¾å› å­ï¼ˆç›®å‰é»˜è®¤æœªå¯ç”¨ï¼‰                     |
    # | `mask_dir`          | str           | æ©ç å›¾è·¯å¾„                                              |
    # | `smpl_type`         | str           | SMPL å‚æ•°ç±»å‹ï¼Œå¦‚ `'romp'`, `'optimized'`                |
    # | `keypoints_dir`     | str           | å…³é”®ç‚¹è·¯å¾„ç›®å½•                                            |
    # | `densepose_dir`     | str           | DensePose è·¯å¾„ç›®å½•                                     |
    @classmethod
    def read_scene(cls, scene_dir, tgt_size=None, normalize=False, bkg_range_scale=1.1, human_range_scale=1.1, mask_dir='segmentations', smpl_type='romp', keypoints_dir='keypoints', densepose_dir='densepose'):
        def update_near_far(scene, keys, range_scale):
            # compute the near and far
            for view_id in tqdm(range(scene.num_views), total=scene.num_views, desc=f'Computing near/far for {keys}'):
                for cam_id in range(scene.num_cams):
                    cur_cap = scene.get_capture_by_view_cam_id(view_id, cam_id)
                    if not hasattr(cur_cap, 'near'):
                        cur_cap.near = {}
                    if not hasattr(cur_cap, 'far'):
                        cur_cap.far = {}
                    for k in keys:
                        if k == 'bkg':
                            pcd_2d_bkg = pcd_projector.project_point_cloud_at_capture(scene.point_cloud, cur_cap, render_type='pcd')
                            near = 0  # np.percentile(pcd_2d_bkg[:, 2], 5)
                            far = np.percentile(pcd_2d_bkg[:, 2], 95)
                        elif k == 'human':
                            pcd_2d_human = pcd_projector.project_point_cloud_at_capture(scene.verts[view_id], cur_cap, render_type='pcd')
                            near = pcd_2d_human[:, 2].min()
                            far = pcd_2d_human[:, 2].max()
                        else:
                            raise ValueError(k)
                        center = (near + far) / 2
                        length = (far - near) * range_scale
                        cur_cap.near[k] = max(0.0, float(center - length / 2))
                        cur_cap.far[k] = float(center + length / 2)
                        
        # read_captures(...) ä» images/ å’Œ sparse/ ä¸­è¯»å–ï¼š
        # æ¯å¸§çš„ RGB å›¾åƒè·¯å¾„ã€æ·±åº¦å›¾è·¯å¾„ã€ç›¸æœºå†…å‚ã€ä½å§¿ç­‰ï¼›
        # è¿”å› capturesï¼ˆä¸€ä¸ª NeuManCapture å¯¹è±¡åˆ—è¡¨ï¼‰ï¼›
        # æ„é€  RigCameraScene å¯¹è±¡ï¼Œè¡¨ç¤ºæ•´ä¸ªåœºæ™¯ã€‚
        # âœ… è¾“å‡ºï¼šscene.captures, scene.point_cloud, scene.num_views
        captures, point_cloud, num_views, num_cams = cls.read_captures(scene_dir, tgt_size, mask_dir=mask_dir, keypoints_dir=keypoints_dir, densepose_dir=densepose_dir)
        
        # æ„é€ ä¸€ä¸ªå¤šæ‘„åƒå¤´-å¤šè§†è§’åœºæ™¯å¯¹è±¡ï¼Œç”¨äºç»Ÿä¸€ç®¡ç†å’Œè®¿é—®æ¯ä¸€å¸§çš„å›¾åƒã€æ·±åº¦å›¾ã€ç›¸æœºå‚æ•°ä»¥åŠå¯¹åº”çš„ä¸‰ç»´ç‚¹äº‘æ•°æ®ã€‚
        # scene.get_captures_by_view_id(3)     # ç¬¬4å¸§çš„å›¾åƒä¿¡æ¯ï¼ˆview 3ï¼‰
        # scene.get_capture_by_view_cam_id(5, 0)  # ç¬¬6å¸§ç¬¬0ä¸ªæ‘„åƒå¤´çš„é‡‡é›†ä¿¡æ¯
        # scene.point_cloud   # å¦‚æœæœ‰æä¾›ç‚¹äº‘æ•°æ®
        # scene[3]            # ä¹Ÿå¯ä»¥æŒ‰ç´¢å¼•è®¿é—® captures
        scene = scene_module.RigCameraScene(captures, num_views, num_cams)
        
        scene.point_cloud = point_cloud
        
        # æ ¹æ®åœºæ™¯ä¸­èƒŒæ™¯ç‚¹äº‘çš„ä½ç½®ï¼Œè‡ªåŠ¨è®¡ç®—æ¯ä¸€å¸§ç›¸æœºåœ¨æ¸²æŸ“â€œèƒŒæ™¯ï¼ˆbkgï¼‰â€æ—¶æ‰€éœ€çš„ near / far clipping planeï¼ˆè¿‘å¹³é¢/è¿œå¹³é¢ï¼‰ï¼Œå¹¶è®¾ç½®åˆ°æ¯ä¸ª captureï¼ˆå¸§ï¼‰ä¸­ã€‚
        # ğŸ“Œ æœ€ç»ˆæ•ˆæœ
        #     æ¯ä¸€ä¸ª captureï¼ˆæ¯å¸§å›¾åƒï¼‰å°†æ‹¥æœ‰å¦‚ä¸‹å±æ€§ï¼š
        # æŠ•å½±åˆ°å½“å‰è§†å›¾ç›¸æœºåæ ‡ç³»ä¸‹ï¼Œå–å‡ºæ‰€æœ‰ç‚¹çš„ z å€¼ï¼ˆæ·±åº¦ï¼‰
        #     capture.near = {'bkg': 0.3, 'human': 0.2}
        #     capture.far  = {'bkg': 5.1, 'human': 2.3}
        #     ç”¨äºåç»­æ¸²æŸ“æˆ–è®­ç»ƒè¿‡ç¨‹ä¸­çš„è§†é”¥ä½“è£å‰ªè®¡ç®—ï¼ˆå³ Frustumï¼‰ã€‚
        update_near_far(scene, ['bkg'], bkg_range_scale)

        if normalize:
            fars = []
            for cap in scene.captures:
                fars.append(cap.far['bkg'])
            fars = np.array(fars)
            scale = 3.14 / (np.percentile(fars, 95))
            for cap in scene.captures:
                cap.cam_pose.camera_center_in_world *= scale
                cap.near['bkg'], cap.far['bkg'] = cap.near['bkg'] * scale, cap.far['bkg'] * scale
                cap.captured_depth.scale = scale
                cap.captured_mono_depth.scale = scale
            scene.point_cloud[:, :3] *= scale
        else:
            scale = 1

        scene.scale = scale
        # smpls, world_verts, static_verts, Ts = cls.read_smpls(scene_dir, scene.captures, scale=scale, smpl_type=smpl_type)
        # scene.smpls, scene.verts, scene.static_vert, scene.Ts = smpls, world_verts, static_verts, Ts
        # _, uvs, faces = read_obj(
        #     'data/smpl/smpl_uv.obj'
        # )
        # scene.uvs, scene.faces = uvs, faces
        # update_near_far(scene, ['human'], human_range_scale)

        assert len(scene.captures) > 0

        return scene

    @classmethod
    def read_smpls(cls, scene_dir, caps, scale=1, smpl_type='romp'):
        def extract_smpl_at_frame(raw_smpl, frame_id):
            out = {}
            for k, v in raw_smpl.items():
                try:
                    out[k] = v[frame_id]
                except:
                    out[k] = None
            return out

        device = torch.device('cpu')
        body_model = SMPL(
            'data/smpl',
            gender='neutral',
            device=device
        )
        smpls = []
        static_verts = []
        world_verts = []
        Ts = []
        smpl_path = os.path.join(scene_dir, f'smpl_output_{smpl_type}.pkl')
        assert os.path.isfile(smpl_path), f'{smpl_path} is missing'
        print(f'using {smpl_type} smpl')
        raw_smpl = joblib.load(smpl_path)
        assert len(raw_smpl) == 1
        raw_smpl = raw_smpl[list(raw_smpl.keys())[0]]
        raw_alignments = np.load(os.path.join(scene_dir, 'alignments.npy'), allow_pickle=True).item()
        for cap in caps:
            frame_id = int(os.path.basename(cap.image_path)[:-4])
            # assert 0 <= frame_id < len(caps)
            temp_smpl = extract_smpl_at_frame(raw_smpl, frame_id)
            temp_alignment = np.eye(4)
            temp_alignment[:, :3] = raw_alignments[os.path.basename(cap.image_path)]
            
            # å¤§ pose
            da_smpl = np.zeros_like(temp_smpl['pose'][None])
            da_smpl = da_smpl.reshape(-1, 3)
            da_smpl[1] = np.array([0, 0, 1.0])
            da_smpl[2] = np.array([0, 0, -1.0])
            da_smpl = da_smpl.reshape(1, -1)

            _, T_t2pose = body_model.verts_transformations(
                return_tensor=False,
                poses=temp_smpl['pose'][None],
                betas=temp_smpl['betas'][None],
                concat_joints=True
            )
            _, T_t2da = body_model.verts_transformations(
                return_tensor=False,
                poses=da_smpl,
                betas=temp_smpl['betas'][None],
                concat_joints=True
            )
            T_da2pose = T_t2pose @ np.linalg.inv(T_t2da)
            T_da2scene = temp_alignment.T @ T_da2pose
            s = np.eye(4)
            s[:3, :3] *= scale
            T_da2scene = s @ T_da2scene

            da_pose_verts, da_pose_joints = body_model(
                return_tensor=False,
                return_joints=True,
                poses=da_smpl,
                betas=temp_smpl['betas'][None]
            )
            temp_world_verts = np.einsum('BNi, Bi->BN', T_da2scene, ray_utils.to_homogeneous(np.concatenate([da_pose_verts, da_pose_joints], axis=0)))[:, :3].astype(np.float32)
            temp_world_verts, temp_world_joints = temp_world_verts[:6890, :], temp_world_verts[6890:, :]
            temp_smpl['joints_3d'] = temp_world_joints
            temp_smpl['static_joints_3d'] = da_pose_joints
            smpls.append(temp_smpl)
            Ts.append(T_da2scene)
            static_verts.append(da_pose_verts)
            world_verts.append(temp_world_verts)
        return smpls, world_verts, static_verts, Ts

    @classmethod
    def read_captures(cls, scene_dir, tgt_size, mask_dir='segmentations', keypoints_dir='keypoints', densepose_dir='densepose'):
    # ä½œç”¨æ˜¯ä»æŒ‡å®šåœºæ™¯è·¯å¾„ä¸­è¯»å–å¹¶å°è£…æ¯å¸§å›¾åƒçš„ç›¸æœºå‚æ•°ã€æ·±åº¦å›¾ã€æ©ç ã€å…³é”®ç‚¹ã€densepose ç­‰ä¿¡æ¯ï¼Œå¹¶ç”Ÿæˆ NeuManCapture æˆ– ResizedNeuManCapture å¯¹è±¡åˆ—è¡¨ä½œä¸ºè¾“å‡ºã€‚
        caps = []
        # 1ï¸âƒ£ ä½¿ç”¨ COLMAP å·¥å…·åŠ è½½åŸºç¡€ç›¸æœºä¸å›¾åƒç»“æ„
        # è¾“å…¥ï¼š
        # scene_dir/sparse: COLMAP çš„ .txt ç›¸æœºå’Œä½å§¿è¾“å‡ºï¼›
        # scene_dir/images: å›¾åƒåºåˆ—æ‰€åœ¨è·¯å¾„ï¼›
        # tgt_size: å¯é€‰å›¾åƒç¼©æ”¾å°ºå¯¸ï¼Œå¦‚ (512, 512)ã€‚
        # è¾“å‡ºï¼ˆraw_scene æ˜¯ RigCameraScene å®ä¾‹ï¼‰ï¼š
        # raw_scene.captures: List[Capture]
        # raw_scene.point_cloud: np.ndarray, shape = (N, 6)  # xyzrgb
        raw_scene = colmap_helper.ColmapAsciiReader.read_scene(
            os.path.join(scene_dir, 'sparse'),
            os.path.join(scene_dir, 'images'),
            tgt_size,
            order='video',
        )

        # 2ï¸âƒ£ åˆå§‹åŒ–å‚æ•°
        num_views = len(raw_scene.captures)  # è§†è§’æ•°ï¼ˆç­‰äºå›¾åƒæ•°ï¼‰
        num_cams = 1 # é»˜è®¤å•æ‘„åƒå¤´
        counter = 0 # å›¾åƒå¸§ç¼–å·è®¡æ•°å™¨
        
        for view_id in range(num_views):
            for cam_id in range(num_cams):
                raw_cap = raw_scene.captures[counter]
                
                # 4ï¸âƒ£ æ„é€ è¯¥å¸§å¯¹åº”çš„å…¶ä»–æ•°æ®è·¯å¾„ï¼ˆdepth, mono_depth, mask, keypoints, denseposeï¼‰
                # raw_cap.image_path: '.../images/00003.jpg'
                # depth_path:         '.../depth_maps/00003.jpg.geometric.bin'
                # mono_depth_path:    '.../mono_depth/00003.jpg'

                # âœ… 1. depth_path: å¤šè§†å›¾å‡ ä½•æ·±åº¦å›¾ï¼ˆMVS Depthï¼‰
                # æ¥æºï¼šæ¥è‡ª COLMAP ç­‰å¤šè§†å›¾ç«‹ä½“ï¼ˆMulti-View Stereo, MVSï¼‰ç®—æ³•ã€‚ é¢„å…ˆå¾—åˆ°çš„
                # è¾“å…¥æ•°æ®ï¼šä½¿ç”¨åŒä¸€åœºæ™¯ä¸­å¤šå¼ å›¾åƒï¼Œä»ä¸åŒè§’åº¦ä¸‰è§’åŒ–è®¡ç®—æ·±åº¦ã€‚
                # ä¼˜ç‚¹ï¼š
                # é€šå¸¸ç²¾åº¦é«˜ï¼Œç‰¹åˆ«æ˜¯è¡¨é¢å‡ ä½•ç»“æ„æ¸…æ™°æ—¶ã€‚
                # ç¼ºç‚¹ï¼š
                # å¯¹çº¹ç†æ•æ„ŸåŒºåŸŸæ•ˆæœå¥½ï¼Œä½†åœ¨é®æŒ¡ã€ä½çº¹ç†æˆ–äººèº«ä¸Šç»å¸¸å¤±è´¥æˆ–ç¼ºå¤±ã€‚
                # å­˜åœ¨â€œæ´â€æˆ–ç¨€ç–åŒºåŸŸã€‚
                # æ–‡ä»¶æ ¼å¼ï¼šé€šå¸¸æ˜¯ .geometric.bin æˆ– .pfm ç­‰äºŒè¿›åˆ¶æ ¼å¼ã€‚
                depth_path = raw_cap.image_path.replace('/images/', '/depth_maps/') + '.geometric.bin'
                # âœ… 2. mono_depth_path: å•ç›®æ·±åº¦å›¾ï¼ˆMonocular Depthï¼‰ 
                # æ¥æºï¼šæ¥è‡ªè®­ç»ƒå¥½çš„å•ç›®æ·±åº¦ä¼°è®¡ç½‘ç»œï¼Œå¦‚ MiDaSã€DPTã€LeReSã€‚  é¢„å…ˆå¾—åˆ°çš„
                # è¾“å…¥æ•°æ®ï¼šåªä¾èµ–å•å¼ å›¾åƒï¼Œæ— éœ€å¤šè§†è§’ã€‚
                mono_depth_path = raw_cap.image_path.replace('/images/', '/mono_depth/')

                if not os.path.isfile(depth_path):
                    depth_path = raw_cap.image_path + 'dummy'
                    print(f'can not find mvs depth for {os.path.basename(raw_cap.image_path)}')
                if not os.path.isfile(mono_depth_path):
                    mono_depth_path = raw_cap.image_path + 'dummy'
                    print(f'can not find mono depth for {os.path.basename(raw_cap.image_path)}')

                
                # è¿™ä¸‰ä¸ªè·¯å¾„å˜é‡åˆ†åˆ«å¯¹åº”å›¾åƒä¸­äººä½“åŒºåŸŸçš„åˆ†å‰²æ©ç ï¼ˆmaskï¼‰ã€äººä½“å…³é”®ç‚¹ï¼ˆkeypointsï¼‰å’ŒDensePose è¡¨ç¤ºï¼ˆdenseposeï¼‰ã€‚
                # âœ… mask_pathï¼šäººä½“æ©ç å›¾ï¼ˆSegmentation Maskï¼‰
                #     ä½œç”¨ï¼šæŒ‡å®šå›¾åƒä¸­å±äºâ€œäººâ€çš„åŒºåŸŸã€‚ç”¨äºï¼š
                #     å‰”é™¤èƒŒæ™¯ï¼ˆè®­ç»ƒæ—¶èšç„¦äºäººï¼‰
                #     å¯¹äººä½“åŒºåŸŸå•ç‹¬ç›‘ç£ä¼˜åŒ–
                #     æ ¼å¼ï¼š
                #     npy æ–‡ä»¶ï¼šå½¢å¦‚ 000001.jpg.npy
                #     æˆ–å›¾åƒæ–‡ä»¶ï¼š000001.jpg.png
                #     å†…å®¹ï¼šç°åº¦å›¾ï¼ˆä¸€èˆ¬ä¸º 0 è¡¨ç¤ºèƒŒæ™¯ï¼Œ255 è¡¨ç¤ºäººä½“ï¼‰
                mask_path = os.path.join(scene_dir, mask_dir, os.path.basename(raw_cap.image_path) + '.npy')
                if not os.path.isfile(mask_path):
                    mask_path = os.path.join(scene_dir, mask_dir, os.path.basename(raw_cap.image_path))

                # âœ… keypoints_pathï¼šäººä½“2Då…³é”®ç‚¹ï¼ˆe.g. COCOæ ¼å¼ï¼‰
                #     ä½œç”¨ï¼š
                #     æä¾›äººä½“éª¨éª¼ç»“æ„çº¦æŸä¿¡æ¯
                #     å¯ç”¨äºç›‘ç£å§¿æ€ä¼°è®¡æˆ–ä¼˜åŒ–åˆå§‹åŒ–
                #     æ ¼å¼ï¼š.npy æ–‡ä»¶ï¼ˆé€šå¸¸æ˜¯ 17 Ã— 3 æ•°ç»„ï¼Œè¡¨ç¤º17ä¸ªå…³é”®ç‚¹çš„ x, y, confidenceï¼‰
                keypoints_path = os.path.join(scene_dir, keypoints_dir, os.path.basename(raw_cap.image_path) + '.npy')
                if not os.path.isfile(keypoints_path):
                    print(f'can not find keypoints for {os.path.basename(raw_cap.image_path)}')
                    keypoints_path = None

                # âœ… densepose_pathï¼šDensePose è¡¨ç¤ºï¼ˆäººä½“åƒç´ çº§ UV åæ ‡ï¼‰
                #     ä½œç”¨ï¼š
                #     æ¯ä¸ªäººä½“åƒç´ å¯¹åº”ä¸€ä¸ª SMPL ç½‘æ ¼ä¸Šçš„ UV åæ ‡å’Œ part label
                #     æä¾›åƒç´ çº§çš„é«˜å¯†åº¦è¯­ä¹‰çº¦æŸï¼Œç”¨äºç²¾ç»†å»ºæ¨¡
                densepose_path = os.path.join(scene_dir, densepose_dir, 'dp_' + os.path.basename(raw_cap.image_path) + '.npy')
                if not os.path.isfile(densepose_path):
                    print(f'can not find densepose for {os.path.basename(raw_cap.image_path)}')
                    densepose_path = None
                    
                # 6ï¸âƒ£ æ ¹æ®æ˜¯å¦æŒ‡å®š tgt_size é€‰æ‹©ä½¿ç”¨ NeuManCapture è¿˜æ˜¯ ResizedNeuManCapture
                if tgt_size is None:
                    temp = NeuManCapture(
                        raw_cap.image_path,
                        depth_path,
                        mask_path,
                        raw_cap.pinhole_cam,
                        raw_cap.cam_pose,
                        view_id,
                        cam_id,
                        mono_depth_path=mono_depth_path,
                        keypoints_path=keypoints_path,
                        densepose_path=densepose_path
                    )
                else:
                    temp = ResizedNeuManCapture(
                        raw_cap.image_path,
                        depth_path,
                        mask_path,
                        raw_cap.pinhole_cam,
                        raw_cap.cam_pose,
                        tgt_size,
                        view_id,
                        cam_id,
                        mono_depth_path=mono_depth_path,
                        keypoints_path=keypoints_path,
                        densepose_path=densepose_path
                    )
                temp.frame_id = raw_cap.frame_id
                counter += 1
                caps.append(temp)
            
        # raw_scene.point_cloudï¼špoints3D.txt
        return caps, raw_scene.point_cloud, num_views, num_cams
