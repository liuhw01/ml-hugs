#
# For licensing see accompanying LICENSE file.
# Copyright (C) 2024 Apple Inc. All Rights Reserved.
#

import torch
import trimesh
from torch import nn
from loguru import logger
import torch.nn.functional as F
from hugs.models.hugs_wo_trimlp import smpl_lbsmap_top_k, smpl_lbsweight_top_k

from hugs.utils.general import (
    inverse_sigmoid, 
    get_expon_lr_func, 
    strip_symmetric,
    build_scaling_rotation,
)
from hugs.utils.rotations import (
    axis_angle_to_rotation_6d, 
    matrix_to_quaternion, 
    matrix_to_rotation_6d, 
    quaternion_multiply,
    quaternion_to_matrix, 
    rotation_6d_to_axis_angle, 
    rotation_6d_to_matrix,
    torch_rotation_matrix_from_vectors,
)
from hugs.cfg.constants import SMPL_PATH
from hugs.utils.subdivide_smpl import subdivide_smpl_model

from .modules.lbs import lbs_extra
from .modules.smpl_layer import SMPL
from .modules.triplane import TriPlane
from .modules.decoders import AppearanceDecoder, DeformationDecoder, GeometryDecoder


SCALE_Z = 1e-5

# åˆå§‹åŒ–æ—¶ä¼šè°ƒç”¨ï¼š
# TriPlane ä¸‰å¹³é¢ä½“ç´ ç¼–ç å™¨
# AppearanceDecoder å¤–è§‚è§£ç å™¨ï¼ˆç”Ÿæˆ SH ç³»æ•°å’Œé€æ˜åº¦ï¼‰
# GeometryDecoder å‡ ä½•è§£ç å™¨ï¼ˆç”Ÿæˆåç§»ã€æ—‹è½¬ã€å°ºåº¦ï¼‰
# DeformationDecoder å½¢å˜è§£ç å™¨ï¼ˆç”Ÿæˆ LBS æƒé‡å’Œ posedirsï¼‰



class HUGS_TRIMLP:

    def setup_functions(self):
        def build_covariance_from_scaling_rotation(scaling, scaling_modifier, rotation):
            L = build_scaling_rotation(scaling_modifier * scaling, rotation)
            actual_covariance = L @ L.transpose(1, 2)
            symm = strip_symmetric(actual_covariance)
            return symm
        
        self.scaling_activation = torch.exp
        self.scaling_inverse_activation = torch.log

        self.covariance_activation = build_covariance_from_scaling_rotation

        self.opacity_activation = torch.sigmoid
        self.inverse_opacity_activation = inverse_sigmoid

        self.rotation_activation = torch.nn.functional.normalize
        
    # | å‚æ•°å                                | ä½œç”¨                                  |
    # | ---------------------------------- | ----------------------------------- |
    # | `sh_degree`                        | æœ€å¤§ spherical harmonics é˜¶æ•°ï¼Œç”¨äºå»ºæ¨¡é«˜æ–¯çš„é¢œè‰² |
    # | `n_subdivision`                    | SMPL æ¨¡æ¿ç½‘æ ¼ç»†åˆ†æ¬¡æ•°ï¼Œå¢åŠ é«˜æ–¯ç‚¹æ•°                |
    # | `init_2d`, `use_surface`           | æ§åˆ¶é«˜æ–¯åˆå§‹åŒ–æ–¹å¼ï¼šæ˜¯å¦ç”¨2Dç‰¹å¾æˆ–è¡¨é¢æ³•å‘åšé™åˆ¶           |
    # | `use_deformer`, `disable_posedirs` | æ˜¯å¦ä½¿ç”¨ SMPL çš„ LBSï¼ˆçº¿æ€§ blendshapeï¼‰æœºåˆ¶    |
    # | `triplane_res`, `n_features`       | ä¸‰å¹³é¢ç‰¹å¾åˆ†è¾¨ç‡åŠé€šé“æ•°ï¼Œç”¨äºä½“ç§¯ç¼–ç                  |
    # | `betas`                            | SMPL shape å‚æ•°åˆå§‹å€¼                    |
    def __init__(
        self, 
        sh_degree: int, 
        only_rgb: bool=False,
        n_subdivision: int=0,  
        use_surface=False,  
        init_2d=False,
        rotate_sh=False,
        isotropic=False,
        init_scale_multiplier=0.5,
        n_features=32,
        use_deformer=False,
        disable_posedirs=False,
        triplane_res=256,
        betas=None,
    ):
        self.only_rgb = only_rgb
        self.active_sh_degree = 0
        self.max_sh_degree = sh_degree  
        self._xyz = torch.empty(0)
        self.scaling_multiplier = torch.empty(0)

        self.max_radii2D = torch.empty(0)
        self.xyz_gradient_accum = torch.empty(0)
        self.denom = torch.empty(0)
        self.optimizer = None
        self.percent_dense = 0
        self.spatial_lr_scale = 0
        self.device = 'cuda'
        self.use_surface = use_surface
        self.init_2d = init_2d
        self.rotate_sh = rotate_sh
        self.isotropic = isotropic
        self.init_scale_multiplier = init_scale_multiplier
        self.use_deformer = use_deformer
        self.disable_posedirs = disable_posedirs
        
        self.deformer = 'smpl'
        
        if betas is not None:
            self.create_betas(betas, requires_grad=False)
        
        self.triplane = TriPlane(n_features, resX=triplane_res, resY=triplane_res, resZ=triplane_res).to('cuda')
        self.appearance_dec = AppearanceDecoder(n_features=n_features*3).to('cuda')
        self.deformation_dec = DeformationDecoder(n_features=n_features*3, 
                                                  disable_posedirs=disable_posedirs).to('cuda')
        self.geometry_dec = GeometryDecoder(n_features=n_features*3, use_surface=use_surface).to('cuda')
        
        if n_subdivision > 0:
            logger.info(f"Subdividing SMPL model {n_subdivision} times")
            # ç”Ÿæˆæ›´å¯†é›†çš„é«˜æ–¯åˆå§‹åŒ–ç‚¹ï¼Œé€šè¿‡ç½‘æ ¼ç»†åˆ†è®©é«˜æ–¯ç‚¹åˆ†å¸ƒæ›´å‡åŒ€ã€æ›´ç»†è‡´ï¼Œä»è€Œæå‡æ¸²æŸ“è´¨é‡ä¸å½¢å˜è¡¨è¾¾èƒ½åŠ›ã€‚
            # subdivide_smpl_model(...)  âŸ¶  _subdivide_smpl_model(...)  âŸ¶  subdivide(...)
            self.smpl_template = subdivide_smpl_model(smoothing=True, n_iter=n_subdivision).to(self.device)
        else:
            self.smpl_template = SMPL(SMPL_PATH).to(self.device)
            
        self.smpl = SMPL(SMPL_PATH).to(self.device)
            
        edges = trimesh.Trimesh(
            vertices=self.smpl_template.v_template.detach().cpu().numpy(), 
            faces=self.smpl_template.faces, process=False
        ).edges_unique
        self.edges = torch.from_numpy(edges).to(self.device).long()
        
        self.init_values = {}
        self.get_vitruvian_verts()
        
        self.setup_functions()
    
    def create_body_pose(self, body_pose, requires_grad=False):
        body_pose = axis_angle_to_rotation_6d(body_pose.reshape(-1, 3)).reshape(-1, 23*6)
        self.body_pose = nn.Parameter(body_pose, requires_grad=requires_grad)
        logger.info(f"Created body pose with shape: {body_pose.shape}, requires_grad: {requires_grad}")
        
    def create_global_orient(self, global_orient, requires_grad=False):
        global_orient = axis_angle_to_rotation_6d(global_orient.reshape(-1, 3)).reshape(-1, 6)
        self.global_orient = nn.Parameter(global_orient, requires_grad=requires_grad)
        logger.info(f"Created global_orient with shape: {global_orient.shape}, requires_grad: {requires_grad}")
        
    def create_betas(self, betas, requires_grad=False):
        self.betas = nn.Parameter(betas, requires_grad=requires_grad)
        logger.info(f"Created betas with shape: {betas.shape}, requires_grad: {requires_grad}")
        
    def create_transl(self, transl, requires_grad=False):
        self.transl = nn.Parameter(transl, requires_grad=requires_grad)
        logger.info(f"Created transl with shape: {transl.shape}, requires_grad: {requires_grad}")
        
    def create_eps_offsets(self, eps_offsets, requires_grad=False):
        logger.info(f"NOT CREATED eps_offsets with shape: {eps_offsets.shape}, requires_grad: {requires_grad}")
    
    @property
    def get_xyz(self):
        return self._xyz
    
    def state_dict(self):
        save_dict = {
            'active_sh_degree': self.active_sh_degree,
            'xyz': self._xyz,
            'triplane': self.triplane.state_dict(),
            'appearance_dec': self.appearance_dec.state_dict(),
            'geometry_dec': self.geometry_dec.state_dict(),
            'deformation_dec': self.deformation_dec.state_dict(),
            'scaling_multiplier': self.scaling_multiplier,
            'max_radii2D': self.max_radii2D,
            'xyz_gradient_accum': self.xyz_gradient_accum,
            'denom': self.denom,
            'optimizer': self.optimizer.state_dict(),
            'spatial_lr_scale': self.spatial_lr_scale,
        }
        return save_dict
    
    def load_state_dict(self, state_dict, cfg=None):
        self.active_sh_degree = state_dict['active_sh_degree']
        self._xyz = state_dict['xyz']
        self.max_radii2D = state_dict['max_radii2D']
        xyz_gradient_accum = state_dict['xyz_gradient_accum']
        denom = state_dict['denom']
        opt_dict = state_dict['optimizer']
        self.spatial_lr_scale = state_dict['spatial_lr_scale']
        
        self.triplane.load_state_dict(state_dict['triplane'])
        self.appearance_dec.load_state_dict(state_dict['appearance_dec'])
        self.geometry_dec.load_state_dict(state_dict['geometry_dec'])
        self.deformation_dec.load_state_dict(state_dict['deformation_dec'])
        self.scaling_multiplier = state_dict['scaling_multiplier']
        
        if cfg is None:
            from hugs.cfg.config import cfg as default_cfg
            cfg = default_cfg.human.lr
            
        self.setup_optimizer(cfg)
        self.xyz_gradient_accum = xyz_gradient_accum
        self.denom = denom
        try:
            self.optimizer.load_state_dict(opt_dict)
        except ValueError as e:
            logger.warning(f"Optimizer load failed: {e}")
            logger.warning("Continue without a pretrained optimizer")
            
    def __repr__(self):
        repr_str = "HUGS TRIMLP: \n"
        repr_str += "xyz: {} \n".format(self._xyz.shape)
        repr_str += "max_radii2D: {} \n".format(self.max_radii2D.shape)
        repr_str += "xyz_gradient_accum: {} \n".format(self.xyz_gradient_accum.shape)
        repr_str += "denom: {} \n".format(self.denom.shape)
        return repr_str

    def canon_forward(self):
        tri_feats = self.triplane(self.get_xyz)
        appearance_out = self.appearance_dec(tri_feats)
        geometry_out = self.geometry_dec(tri_feats)
        
        xyz_offsets = geometry_out['xyz']
        gs_rot6d = geometry_out['rotations']
        gs_scales = geometry_out['scales'] * self.scaling_multiplier
        
        gs_opacity = appearance_out['opacity']
        gs_shs = appearance_out['shs'].reshape(-1, 16, 3)
        
        if self.use_deformer:
            deformation_out = self.deformation_dec(tri_feats)
            lbs_weights = deformation_out['lbs_weights']
            lbs_weights = F.softmax(lbs_weights/0.1, dim=-1)
            posedirs = deformation_out['posedirs']
            if abs(lbs_weights.sum(-1).mean().item() - 1) < 1e-7:
                pass
            else:
                logger.warning(f"LBS weights should sum to 1, but it is: {lbs_weights.sum(-1).mean().item()}")
        else:
            lbs_weights = None
            posedirs = None
            
        return {
            'xyz_offsets': xyz_offsets,
            'scales': gs_scales,
            'rot6d_canon': gs_rot6d,
            'shs': gs_shs,
            'opacity': gs_opacity,
            'lbs_weights': lbs_weights,
            'posedirs': posedirs,
        }

    def forward_test(
        self,
        canon_forward_out,
        global_orient=None, 
        body_pose=None, 
        betas=None, 
        transl=None, 
        smpl_scale=None,
        dataset_idx=-1,
        is_train=False,
        ext_tfs=None,
    ):
        xyz_offsets = canon_forward_out['xyz_offsets']
        gs_rot6d = canon_forward_out['rot6d_canon']
        gs_scales = canon_forward_out['scales']
        
        gs_xyz = self.get_xyz + xyz_offsets
        
        gs_rotmat = rotation_6d_to_matrix(gs_rot6d)
        gs_rotq = matrix_to_quaternion(gs_rotmat)

        gs_opacity = canon_forward_out['opacity']
        gs_shs = canon_forward_out['shs'].reshape(-1, 16, 3)
        
        if self.isotropic:
            gs_scales = torch.ones_like(gs_scales) * torch.mean(gs_scales, dim=-1, keepdim=True)
            
        gs_scales_canon = gs_scales.clone()
        
        if self.use_deformer:
            lbs_weights = canon_forward_out['lbs_weights']
            posedirs = canon_forward_out['posedirs']
            if abs(lbs_weights.sum(-1).mean().item() - 1) < 1e-7:
                pass
            else:
                logger.warning(f"LBS weights should sum to 1, but it is: {lbs_weights.sum(-1).mean().item()}")
        else:
            lbs_weights = None
            posedirs = None
        
        if hasattr(self, 'global_orient') and global_orient is None:
            global_orient = rotation_6d_to_axis_angle(
                self.global_orient[dataset_idx].reshape(-1, 6)).reshape(3)
        
        if hasattr(self, 'body_pose') and body_pose is None:
            body_pose = rotation_6d_to_axis_angle(
                self.body_pose[dataset_idx].reshape(-1, 6)).reshape(23*3)
            
        if hasattr(self, 'betas') and betas is None:
            betas = self.betas
            
        if hasattr(self, 'transl') and transl is None:
            transl = self.transl[dataset_idx]
        
        # vitruvian -> t-pose -> posed
        # remove and reapply the blendshape
        smpl_output = self.smpl(
            betas=betas.unsqueeze(0),
            body_pose=body_pose.unsqueeze(0),
            global_orient=global_orient.unsqueeze(0),
            disable_posedirs=False,
            return_full_pose=True,
        )
        
        gt_lbs_weights = None
        if self.use_deformer:
            A_t2pose = smpl_output.A[0]
            A_vitruvian2pose = A_t2pose @ self.inv_A_t2vitruvian
            deformed_xyz, _, lbs_T, _, _ = lbs_extra(
                A_vitruvian2pose[None], gs_xyz[None], posedirs, lbs_weights, 
                smpl_output.full_pose, disable_posedirs=self.disable_posedirs, pose2rot=True
            )
            deformed_xyz = deformed_xyz.squeeze(0)
            lbs_T = lbs_T.squeeze(0)

            with torch.no_grad():
                # gt lbs is needed for lbs regularization loss
                # predicted lbs should be close to gt lbs
                _, gt_lbs_weights = smpl_lbsweight_top_k(
                    lbs_weights=self.smpl.lbs_weights,
                    points=gs_xyz.unsqueeze(0),
                    template_points=self.vitruvian_verts.unsqueeze(0),
                )
                gt_lbs_weights = gt_lbs_weights.squeeze(0)
                if abs(gt_lbs_weights.sum(-1).mean().item() - 1) < 1e-7:
                    pass
                else:
                    logger.warning(f"GT LBS weights should sum to 1, but it is: {gt_lbs_weights.sum(-1).mean().item()}")
        else:
            curr_offsets = (smpl_output.shape_offsets + smpl_output.pose_offsets)[0]
            T_t2pose = smpl_output.T[0]
            T_vitruvian2t = self.inv_T_t2vitruvian.clone()
            T_vitruvian2t[..., :3, 3] = T_vitruvian2t[..., :3, 3] + self.canonical_offsets - curr_offsets
            T_vitruvian2pose = T_t2pose @ T_vitruvian2t

            _, lbs_T = smpl_lbsmap_top_k(
                lbs_weights=self.smpl.lbs_weights,
                verts_transform=T_vitruvian2pose.unsqueeze(0),
                points=gs_xyz.unsqueeze(0),
                template_points=self.vitruvian_verts.unsqueeze(0),
                K=6,
            )
            lbs_T = lbs_T.squeeze(0)
        
            homogen_coord = torch.ones_like(gs_xyz[..., :1])
            gs_xyz_homo = torch.cat([gs_xyz, homogen_coord], dim=-1)
            deformed_xyz = torch.matmul(lbs_T, gs_xyz_homo.unsqueeze(-1))[..., :3, 0]
        
        if smpl_scale is not None:
            deformed_xyz = deformed_xyz * smpl_scale.unsqueeze(0)
            gs_scales = gs_scales * smpl_scale.unsqueeze(0)
        
        if transl is not None:
            deformed_xyz = deformed_xyz + transl.unsqueeze(0)
        
        deformed_gs_rotmat = lbs_T[:, :3, :3] @ gs_rotmat
        deformed_gs_rotq = matrix_to_quaternion(deformed_gs_rotmat)
        
        if ext_tfs is not None:
            tr, rotmat, sc = ext_tfs
            deformed_xyz = (tr[..., None] + (sc[None] * (rotmat @ deformed_xyz[..., None]))).squeeze(-1)
            gs_scales = sc * gs_scales
            
            rotq = matrix_to_quaternion(rotmat)
            deformed_gs_rotq = quaternion_multiply(rotq, deformed_gs_rotq)
            deformed_gs_rotmat = quaternion_to_matrix(deformed_gs_rotq)

        # æ„é€ ä¸€ä¸ªä¸ gs_xyz åŒ shape çš„å‘é‡ç»„ï¼Œæ‰€æœ‰æ³•å‘åˆå§‹è®¾ä¸º (0,0,1)ï¼Œè¡¨ç¤º canonical çŠ¶æ€ä¸‹çš„â€œä¸Šâ€æ–¹å‘ã€‚
        self.normals = torch.zeros_like(gs_xyz)
        self.normals[:, 2] = 1.0

        # canon_normalsï¼šå°†é»˜è®¤æ³•å‘é€šè¿‡ canonical æ—‹è½¬ gs_rotmat å˜æ¢ï¼Œå¾—åˆ° canonical å§¿æ€ä¸‹æ¯ä¸ªé«˜æ–¯çš„çœŸå®æ³•å‘ã€‚
        canon_normals = (gs_rotmat @ self.normals.unsqueeze(-1)).squeeze(-1)
        # deformed_normalsï¼šå†ç”¨æœ€ç»ˆçš„ posed æ—‹è½¬ deformed_gs_rotmat å˜æ¢ï¼Œå¾—åˆ°å˜å½¢åæ¯ä¸ªé«˜æ–¯çš„æ³•å‘ã€‚
        deformed_normals = (deformed_gs_rotmat @ self.normals.unsqueeze(-1)).squeeze(-1)
        # ç”±äºå¤–éƒ¨å˜æ¢åªå½±å“ç©ºé—´ä½ç½®å’Œæ—‹è½¬ï¼Œä¸æ”¹å˜ spherical harmonics ç³»æ•°ï¼Œç›´æ¥å…‹éš†ä¸€ä»½å³å¯ã€‚
        deformed_gs_shs = gs_shs.clone()


        return {
            'xyz': deformed_xyz,
            'xyz_canon': gs_xyz,
            'xyz_offsets': xyz_offsets,
            'scales': gs_scales,
            'scales_canon': gs_scales_canon,
            'rotq': deformed_gs_rotq,
            'rotq_canon': gs_rotq,
            'rotmat': deformed_gs_rotmat,
            'rotmat_canon': gs_rotmat,
            'shs': deformed_gs_shs,
            'opacity': gs_opacity,
            'normals': deformed_normals,
            'normals_canon': canon_normals,
            'active_sh_degree': self.active_sh_degree,
            'rot6d_canon': gs_rot6d,
            'lbs_weights': lbs_weights,
            'posedirs': posedirs,
            'gt_lbs_weights': gt_lbs_weights,
        }
         
    def forward(
        self,
        global_orient=None, 
        body_pose=None, 
        betas=None, 
        transl=None, 
        smpl_scale=None,
        dataset_idx=-1,
        is_train=False,
        ext_tfs=None,
    ):
        # tri_feats.shape=(N,Â 3Ã—features)
        tri_feats = self.triplane(self.get_xyz)

        # return {'shs': shs, 'opacity': opacity}
        appearance_out = self.appearance_dec(tri_feats)
        
        # return {
            # 'xyz': xyz,
            # 'rotations': rotations,
            # 'scales': scales,
        # }

# ğŸ”¹é˜¶æ®µä¸€ï¼šè§„èŒƒç©ºé—´é«˜æ–¯æ„å»ºï¼ˆCanonical Gaussiansï¼‰
        geometry_out = self.geometry_dec(tri_feats)
        
        xyz_offsets = geometry_out['xyz']
        gs_rot6d = geometry_out['rotations']
        gs_scales = geometry_out['scales'] * self.scaling_multiplier
        
        gs_xyz = self.get_xyz + xyz_offsets
        
        gs_rotmat = rotation_6d_to_matrix(gs_rot6d)
        gs_rotq = matrix_to_quaternion(gs_rotmat)

        gs_opacity = appearance_out['opacity']
        gs_shs = appearance_out['shs'].reshape(-1, 16, 3)
        
        if self.isotropic:
            gs_scales = torch.ones_like(gs_scales) * torch.mean(gs_scales, dim=-1, keepdim=True)
            
        gs_scales_canon = gs_scales.clone()

# â— å…³é”®åŒºåˆ«ï¼ˆèƒ½åŠ› vs æ•ˆæœï¼‰
# | æ–¹é¢                                    | `smpl_lbsmap_top_k` | `lbs_extra`   |
# | ------------------------------------- | ------------------- | ------------- |
# | **LBS æƒé‡æ¥æº**                          | SMPLè‡ªå¸¦çš„å›ºå®šæ¨¡æ¿           | ç½‘ç»œå¯å­¦ä¹          |
# | **pose-induced deformation**ï¼ˆå§¿æ€å¼•èµ·çš„å½¢å˜ï¼‰ | âŒ æ— ï¼ˆåˆšæ€§ï¼‰             | âœ… æœ‰ï¼ˆéçº¿æ€§å“åº”ï¼‰    |
# | **posedirs ä½¿ç”¨**                       | âŒ æœªä½¿ç”¨               | âœ… ä½¿ç”¨          |
# | **å˜å½¢ç²¾åº¦**                              | ä»…ä»¿å°„åˆšæ€§å˜æ¢             | åŠ¨ä½œé©±åŠ¨çš„æŸ”æ€§å½¢å˜     |
# | **æ§åˆ¶è‡ªç”±åº¦**                             | æ— æ³•å­¦ä¹ ä¼˜åŒ–ï¼ˆåªæ˜¯åº”ç”¨ï¼‰        | å¯è®­ç»ƒã€å¯å¾®ã€å¯ç²¾è°ƒ    |
# | **åº”ç”¨åœºæ™¯**                              | baselineã€åˆå§‹åŒ–        | çœŸå®é©±åŠ¨/åŠ¨ç”»/æ‹ŸäººåŒ–æ•ˆæœ |


# ğŸ”¹é˜¶æ®µäºŒï¼šæ˜¯å¦ä½¿ç”¨ SMPL LBS åŠ¨ä½œé©±åŠ¨ï¼Œåç»­é€å…¥lbs_extra
# ä½¿ç”¨ deformation_decoder è§£ç å¾—åˆ°ï¼š
#     lbs_weightsï¼šé«˜æ–¯ç‚¹å¯¹ SMPL å„éª¨éª¼çš„ LBS æƒé‡
#     posedirsï¼šé«˜æ–¯ç‚¹åœ¨éª¨éª¼æ—‹è½¬ä¸‹çš„å½¢å˜æ–¹å‘
        if self.use_deformer:
            # return {
            #     'lbs_weights': lbs_weights,
            #     'posedirs': posedirs if not self.disable_posedirs else None,
            # }
            # å¯¹äºæ¯ä¸ªé«˜æ–¯ç‚¹ï¼Œå®ƒå¯¹ SMPL æ¨¡å‹ä¸­ å„ä¸ªå…³èŠ‚ çš„çº¿æ€§æ··åˆæƒé‡ï¼ˆLinear Blend Skinningï¼‰æ˜¯å¤šå°‘ã€‚
            #     lbs_weights.shape = [N, 24]ï¼ˆå¦‚æœ SMPL æ˜¯ 24 ä¸ªå…³èŠ‚ï¼‰
            #     ç”¨äºåç»­è®¡ç®—ï¼š
            #         deformed_xyz = lbs_extra(..., lbs_weights, posedirs, ...)
            #         ï¼ï¼â†’ æŠŠé™æ€çš„ xyz é€šè¿‡éª¨éª¼å§¿æ€å˜æˆåŠ¨æ€ä½ç½®ã€‚ï¼ï¼
            # âš ï¸ ä¸æ˜¯é«˜æ–¯åç§»çš„åŸå› æ˜¯ï¼š
                # é«˜æ–¯åç§»å·²ç»åœ¨ geometry_out['xyz'] ä¸­è¾“å‡ºï¼›
                # deformation_out ä¸“æ³¨äºâ€œå¦‚ä½•è·Ÿéš SMPL åŠ¨èµ·æ¥â€çš„éƒ¨åˆ†ï¼›
            deformation_out = self.deformation_dec(tri_feats)
            lbs_weights = deformation_out['lbs_weights']
            
            # å¯¹ LBS æƒé‡åšå½’ä¸€åŒ–ï¼Œå› ä¸º LBS æ˜¯çº¿æ€§åŠ æƒå¹³å‡ï¼Œæƒé‡ä¹‹å’Œå¿…é¡»ä¸º 1ã€‚
            lbs_weights = F.softmax(lbs_weights/0.1, dim=-1)
            
            # posedirs: é«˜æ–¯ç‚¹åœ¨å…³èŠ‚æ—‹è½¬ä¸‹çš„å±€éƒ¨åç§»å“åº”æ–¹å‘
            posedirs = deformation_out['posedirs']
            if abs(lbs_weights.sum(-1).mean().item() - 1) < 1e-7:
                pass
            else:
                logger.warning(f"LBS weights should sum to 1, but it is: {lbs_weights.sum(-1).mean().item()}")
        else:
            lbs_weights = None
            posedirs = None
        
        if hasattr(self, 'global_orient') and global_orient is None:
            global_orient = rotation_6d_to_axis_angle(
                self.global_orient[dataset_idx].reshape(-1, 6)).reshape(3)
        
        if hasattr(self, 'body_pose') and body_pose is None:
            body_pose = rotation_6d_to_axis_angle(
                self.body_pose[dataset_idx].reshape(-1, 6)).reshape(23*3)
            
        if hasattr(self, 'betas') and betas is None:
            betas = self.betas
            
        if hasattr(self, 'transl') and transl is None:
            transl = self.transl[dataset_idx]

# ğŸ”¹é˜¶æ®µä¸‰ï¼šè·å– SMPL çš„å½“å‰å§¿æ€å‚æ•°
        # vitruvian -> t-pose -> posed
        # remove and reapply the blendshape
        # æœ€ç»ˆï¼Œsmpl_output åŒ…å«ï¼š
        #     verticesï¼š(1, V, 3) é¡¶ç‚¹åæ ‡
        #     Aã€Tï¼šå…³èŠ‚å˜æ¢çŸ©é˜µï¼šï¼š å½¢çŠ¶ï¼šA æ˜¯ä¸€ä¸ªå¼ é‡ï¼Œé€šå¸¸å¤§å° (J, 4, 4)ï¼ŒJ æ˜¯å…³èŠ‚æ•°ï¼ˆSMPL ä¸­ä¸º 24 æˆ– 23ï¼‰ã€‚ï¼šï¼š å½¢çŠ¶ï¼šT æ˜¯ä¸€ä¸ªå¼ é‡ï¼Œå¤§å° (V, 4, 4)ï¼ŒV æ˜¯ç½‘æ ¼é¡¶ç‚¹æ•°ã€‚
        #     shape_offsetsã€pose_offsetsï¼šblendshape åç§»
        #     full_poseï¼š23Ã—3 è½´è§’è¡¨ç¤º
        smpl_output = self.smpl(
            betas=betas.unsqueeze(0),
            body_pose=body_pose.unsqueeze(0),
            global_orient=global_orient.unsqueeze(0),
            disable_posedirs=False,
            return_full_pose=True,
        )

        # â€” å…ˆåˆå§‹åŒ–çœŸå®æƒé‡å˜é‡ï¼Œç”¨äºåé¢è®¡ç®— gt_lbs_weightsï¼ˆground-truth LBS weightsï¼‰ã€‚
        gt_lbs_weights = None

        if self.use_deformer:
            
            # å–å‡º SMPL è¾“å‡ºä¸­ç¬¬ 0ï¼ˆbatchï¼‰å¸§çš„å…³èŠ‚å˜æ¢çŸ©é˜µ Aï¼Œå½¢çŠ¶ (J,4,4)ã€‚
            A_t2pose = smpl_output.A[0]

            # å°†æ¨¡æ¿ï¼ˆVitruvianï¼‰â†’T-poseçš„é€†å˜æ¢ inv_A_t2vitruvian ä¸å½“å‰å§¿æ€å…³èŠ‚å˜æ¢ A_t2pose ç›¸ä¹˜ï¼Œ
            # å¾—åˆ° â€œVitruvian â†’ posedâ€ çš„æ¯ä¸ªå…³èŠ‚å˜æ¢ã€‚
            A_vitruvian2pose = A_t2pose @ self.inv_A_t2vitruvian


            #### å˜æ¢ä½ç½®å’Œæ—‹è½¬åˆ° posed space   lbs_extra
            # | å±æ€§        | æ¥æº                                   | æ˜¯å¦å˜æ¢åˆ° posed space |
            # | --------- | --------------------------------------- | -----------------â€”â€”   |
            # | `xyz`     | `self.get_xyz + xyz_offsets â†’ lbs â†’ âœ”`  | âœ… æ˜¯                  |
            # | `scales`  | `geometry_out['scales'] * smpl_scale`   | âœ… è·Ÿéšä½ç§»ç¼©æ”¾          |
            # | `rotmat`  | `lbs_T[:, :3, :3] @ canonical_rotation` | âœ… æ˜¯                  |
            # | `shs`     | `appearance_out['shs']` â†’ ä¸å˜           | âŒ ä¸éœ€å˜ï¼ˆå‡å®šä¸éšå§¿æ€ï¼‰ |
            # | `opacity` | `appearance_out['opacity']`             | âŒ ä¸å˜                |
            # è¾“å…¥
            #     A_vitruvian2pose[None]ï¼šæ¯ä¸ªå…³èŠ‚â€œæ¨¡æ¿â†’å§¿æ€â€çš„ 4Ã—4 å˜æ¢
            #     gs_xyz[None]ï¼šè¦åšéª¨éª¼ç»‘å®šçš„é«˜æ–¯ç‚¹ä½ç½®ï¼Œxyz_offsetsåçš„é«˜æ–¯ç‚¹ï¼Œå¦‚æœ gs_xyz çš„ shape æ˜¯ (N, 3)ï¼Œé‚£ä¹ˆ gs_xyz[None] å°±ä¼šå˜æˆ shape (1, N, 3)ã€‚
            #     posedirsï¼šæ¯ä¸ªç‚¹åœ¨å…³èŠ‚æ—‹è½¬ä¸‹çš„ä½ç§»æ–¹å‘é›†åˆ
            #     lbs_weightsï¼šé¢„æµ‹å¾—åˆ°çš„æ¯ä¸ªç‚¹å¯¹æ¯ä¸ªå…³èŠ‚çš„æƒé‡
            #     smpl_output.full_poseï¼šSMPL çš„å½“å‰è½´è§’å‚æ•°
            # è¾“å‡º
            #     deformed_xyzï¼šéª¨éª¼ç»‘å®šåé«˜æ–¯ç‚¹çš„æ–°ä½ç½® (1, N, 3)
            #     lbs_Tï¼šæ¯ä¸ªç‚¹çš„æœ€ç»ˆ 4Ã—4 LBS å˜æ¢çŸ©é˜µ (1, N, 4, 4)
            #     ä¸­é—´è¿˜æœ‰å…¶ä»–è¿”å›å€¼ï¼Œç”¨ _ å¿½ç•¥ã€‚
            deformed_xyz, _, lbs_T, _, _ = lbs_extra(
                A_vitruvian2pose[None], gs_xyz[None], posedirs, lbs_weights, 
                smpl_output.full_pose, disable_posedirs=self.disable_posedirs, pose2rot=True
            )
            deformed_xyz = deformed_xyz.squeeze(0)
            lbs_T = lbs_T.squeeze(0)

            with torch.no_grad():
                # gt lbs is needed for lbs regularization loss
                # predicted lbs should be close to gt lbs
                
                # åœ¨ä¸è®¡ç®—æ¢¯åº¦çš„æƒ…å†µä¸‹ï¼Œè®¡ç®—â€œçœŸå®â€LBS æƒé‡ gt_lbs_weightsï¼Œç”¨äºåšæ­£åˆ™åŒ–æŸå¤±ã€‚
                _, gt_lbs_weights = smpl_lbsweight_top_k(
                    lbs_weights=self.smpl.lbs_weights,
                    points=gs_xyz.unsqueeze(0),
                    template_points=self.vitruvian_verts.unsqueeze(0),
                )
                gt_lbs_weights = gt_lbs_weights.squeeze(0)

                # ç¡®è®¤ gt_lbs_weights åœ¨æ¯ä¸ªç‚¹ä¸Šæ€»å’Œä¸º 1ï¼Œå¦åˆ™æ‰“è­¦å‘Šã€‚
                if abs(gt_lbs_weights.sum(-1).mean().item() - 1) < 1e-7:
                    pass
                else:
                    logger.warning(f"GT LBS weights should sum to 1, but it is: {gt_lbs_weights.sum(-1).mean().item()}")
        else:
            # SMPL ä½œå½¢å˜æ—¶çš„æ¨¡æ¿åç§»ï¼šshape_offsets + pose_offsetsï¼Œå–ç¬¬ 0 å¸§ã€‚
            curr_offsets = (smpl_output.shape_offsets + smpl_output.pose_offsets)[0]
            T_t2pose = smpl_output.T[0]
            T_vitruvian2t = self.inv_T_t2vitruvian.clone()
            T_vitruvian2t[..., :3, 3] = T_vitruvian2t[..., :3, 3] + self.canonical_offsets - curr_offsets
            T_vitruvian2pose = T_t2pose @ T_vitruvian2t
            
# ğŸ”¹é˜¶æ®µå››ï¼šæ‰§è¡Œ LBSï¼Œè®¡ç®—å˜å½¢é«˜æ–¯ä½ç½®ä¸æ—‹è½¬ï¼ˆMotion-aware Gaussiansï¼‰ï¼ŒåŸºäºlbs_weightså‚æ•°
            # æ ¹æ® SMPL è‡ªå¸¦çš„ lbs_weightsï¼Œå¯¹ gs_xyz ä¸Šçš„æ¯ä¸ªç‚¹ï¼š            
            # ä½¿ç”¨ T_vitruvian2poseï¼ˆæ¯é¡¶ç‚¹çš„ 4Ã—4 å˜æ¢ï¼‰
            # è®¡ç®—å…¶å¯¹ç‚¹çš„ LBS å˜æ¢çŸ©é˜µ lbs_Tï¼ˆé€‰å– top-K éª¨éª¼ä»¥æé«˜æ•ˆç‡ï¼‰
            # è¿”å› lbs_Tï¼šå½¢çŠ¶ (1, N, 4, 4) â†’ .squeeze(0) å¾— (N,4,4)ã€‚
            _, lbs_T = smpl_lbsmap_top_k(
                lbs_weights=self.smpl.lbs_weights,
                verts_transform=T_vitruvian2pose.unsqueeze(0),
                points=gs_xyz.unsqueeze(0),
                template_points=self.vitruvian_verts.unsqueeze(0),
                K=6,
            )
            lbs_T = lbs_T.squeeze(0)
        
            homogen_coord = torch.ones_like(gs_xyz[..., :1])
            gs_xyz_homo = torch.cat([gs_xyz, homogen_coord], dim=-1)
            
            # å¯¹æ¯ä¸ªç‚¹ï¼ŒæŠŠ (4Ã—4) çš„ lbs_T çŸ©é˜µå·¦ä¹˜å…¶é½æ¬¡åæ ‡ï¼Œå¾—åˆ°å˜å½¢åä½ç½® (x',y',z',w')ï¼Œå–å‰ä¸‰ç»´ (x',y',z') å³ deformed_xyzã€‚
            deformed_xyz = torch.matmul(lbs_T, gs_xyz_homo.unsqueeze(-1))[..., :3, 0]

        # å…¨èº«ç¼©æ”¾ï¼šsmpl_scale é€šå¸¸æ˜¯ä¸€ä¸ªå½¢å¦‚ (3,) æˆ– (1,) çš„å¼ é‡ï¼Œè¡¨ç¤ºå¯¹æ•´ä¸ª SMPL å˜å½¢ç»“æœåšå…¨å±€ç¼©æ”¾ã€‚
        if smpl_scale is not None:
            deformed_xyz = deformed_xyz * smpl_scale.unsqueeze(0)
            gs_scales = gs_scales * smpl_scale.unsqueeze(0)
        
        # å…¨èº«å¹³ç§»ï¼štransl æ˜¯ä¸€ä¸ª (3,) çš„å¹³ç§»å‘é‡ï¼ŒåŠ ä¸Šå®ƒä¼šå°†æ‰€æœ‰ç‚¹æ²¿ XYZ å¹³ç§»ç›¸åŒé‡ã€‚
        if transl is not None:
            deformed_xyz = deformed_xyz + transl.unsqueeze(0)
            
# ğŸ”¹é˜¶æ®µå…­ï¼šæ›´æ–°æ—‹è½¬ã€æ³•å‘ã€æœ€ç»ˆå±æ€§
        # è®¡ç®—å˜å½¢åæ¯ä¸ªé«˜æ–¯çš„æ—‹è½¬çŸ©é˜µ
        #     lbs_T æ˜¯æ¯ä¸ªç‚¹çš„ 4Ã—4 LBS å˜æ¢çŸ©é˜µï¼Œå–å®ƒçš„å‰ 3Ã—3 å­çŸ©é˜µ lbs_T[:, :3, :3] å¾—åˆ°ç‚¹åœ¨ posed çŠ¶æ€ä¸‹çš„åˆšæ€§æ—‹è½¬ã€‚
        #     ä¸ Canonical çŠ¶æ€ä¸‹çš„æ—‹è½¬ gs_rotmat ç›¸ä¹˜ï¼Œå¯å¾—åˆ°â€œå…ˆæ—‹è½¬åˆ° canonical æœå‘ï¼Œå†æŒ‰ LBS æ—‹è½¬åˆ° posed æœå‘â€çš„å¤åˆæ—‹è½¬çŸ©é˜µã€‚
        deformed_gs_rotmat = lbs_T[:, :3, :3] @ gs_rotmat
        # å°†å¤åˆæ—‹è½¬çŸ©é˜µè½¬æ¢ä¸ºå››å…ƒæ•°è¡¨ç¤ºï¼Œä¾¿äºåç»­æ’å€¼æˆ–ä¸å…¶ä»–æ—‹è½¬ç›¸ä¹˜ã€‚
        deformed_gs_rotq = matrix_to_quaternion(deformed_gs_rotmat)

        # åº”ç”¨å¤–éƒ¨ä»¿å°„å˜æ¢ï¼ˆå¯é€‰ï¼‰
        if ext_tfs is not None:
            tr, rotmat, sc = ext_tfs
            deformed_xyz = (tr[..., None] + (sc[None] * (rotmat @ deformed_xyz[..., None]))).squeeze(-1)
            gs_scales = sc * gs_scales
            
            rotq = matrix_to_quaternion(rotmat)
            deformed_gs_rotq = quaternion_multiply(rotq, deformed_gs_rotq)
            deformed_gs_rotmat = quaternion_to_matrix(deformed_gs_rotq)
        
        # æ„é€ ä¸€ä¸ªä¸ gs_xyz åŒ shape çš„å‘é‡ç»„ï¼Œæ‰€æœ‰æ³•å‘åˆå§‹è®¾ä¸º (0,0,1)ï¼Œè¡¨ç¤º canonical çŠ¶æ€ä¸‹çš„â€œä¸Šâ€æ–¹å‘ã€‚
        self.normals = torch.zeros_like(gs_xyz)
        self.normals[:, 2] = 1.0

        # canon_normalsï¼šå°†é»˜è®¤æ³•å‘é€šè¿‡ canonical æ—‹è½¬ gs_rotmat å˜æ¢ï¼Œå¾—åˆ° canonical å§¿æ€ä¸‹æ¯ä¸ªé«˜æ–¯çš„çœŸå®æ³•å‘ã€‚
        canon_normals = (gs_rotmat @ self.normals.unsqueeze(-1)).squeeze(-1)
        # deformed_normalsï¼šå†ç”¨æœ€ç»ˆçš„ posed æ—‹è½¬ deformed_gs_rotmat å˜æ¢ï¼Œå¾—åˆ°å˜å½¢åæ¯ä¸ªé«˜æ–¯çš„æ³•å‘ã€‚
        deformed_normals = (deformed_gs_rotmat @ self.normals.unsqueeze(-1)).squeeze(-1)
        # ç”±äºå¤–éƒ¨å˜æ¢åªå½±å“ç©ºé—´ä½ç½®å’Œæ—‹è½¬ï¼Œä¸æ”¹å˜ spherical harmonics ç³»æ•°ï¼Œç›´æ¥å…‹éš†ä¸€ä»½å³å¯ã€‚
        deformed_gs_shs = gs_shs.clone()


        #         | çŠ¶æ€                   | è¯´æ˜                                                                                                             |
# | -------------------- | -------------------------------------------------------------------------------------------------------------- |
# | **Canonical**ï¼ˆè§„èŒƒåŒ–çŠ¶æ€ï¼‰ | é¡¶ç‚¹ï¼é«˜æ–¯ç‚¹å¤„äº SMPL æ¨¡æ¿å®šä¹‰çš„â€œæ ‡å‡†â€å§¿æ€ä¸‹ï¼ˆé€šå¸¸æ˜¯ Vitruvian pose æˆ– T-poseï¼‰ï¼ŒåªåŒ…å«åˆå§‹çš„å½¢çŠ¶åç§»ï¼ˆshape\_offsetsï¼‰å’Œæ¨¡å‹çº§åˆ«çš„æ¨¡æ¿å‚æ•°ï¼Œæ²¡æœ‰ä»»ä½•å…³èŠ‚é©±åŠ¨çš„å½¢å˜æˆ–å¤–éƒ¨å˜æ¢ã€‚ |
# | **Deformed**ï¼ˆå˜å½¢åçŠ¶æ€ï¼‰  | é¡¶ç‚¹ï¼é«˜æ–¯ç‚¹åº”ç”¨äº†éª¨éª¼ç»‘å®šï¼ˆLBSï¼‰ã€pose-dirsã€å…¨å±€æ—‹è½¬ç¼©æ”¾å¹³ç§»ï¼Œç”šè‡³å¯èƒ½å†å åŠ äº†ä¸€æ¬¡å¤–éƒ¨ä»¿å°„å˜æ¢ä¹‹åçš„ä½ç½®ã€‚                                                   |

        # è¿”å›å­—å…¸
        #     xyz: å˜å½¢å¹¶åº”ç”¨æ‰€æœ‰ç¼©æ”¾ã€å¹³ç§»å’Œå¤–éƒ¨å˜æ¢åçš„é«˜æ–¯ä¸­å¿ƒ
        #     xyz_canon: canonicalï¼ˆæœªå˜å½¢ï¼‰çŠ¶æ€ä¸‹çš„é«˜æ–¯ä¸­å¿ƒ
        #     xyz_offsets: å‡ ä½•åç§»ï¼ˆgeometry decoder è¾“å‡ºï¼‰
        #     scales / scales_canon: æœ€ç»ˆä¸ canonical çš„å°ºåº¦
        #     rotq / rotmat: å˜å½¢åé«˜æ–¯çš„æ—‹è½¬ï¼ˆå››å…ƒæ•°å’ŒçŸ©é˜µï¼‰
        #     rotq_canon / rotmat_canon: canonical å§¿æ€ä¸‹çš„æ—‹è½¬
        #     rot6d_canon: canonical çš„ 6D æ—‹è½¬è¡¨ç¤º
        #     shs: spherical harmonics ç³»æ•°
        #     opacity: é€æ˜åº¦
        #     normals / normals_canon: å˜å½¢åä¸ canonical ä¸‹çš„æ³•å‘
        #     active_sh_degree: å½“å‰ SH é˜¶æ•°
        #     lbs_weights, posedirs: ç”¨äº LBS çš„æƒé‡å’Œåç§»æ–¹å‘
        #     gt_lbs_weights: SMPL åŸç”Ÿæƒé‡çš„ ground-truthï¼Œç”¨äºæ­£åˆ™åŒ–
        return {
            'xyz': deformed_xyz,
            'xyz_canon': gs_xyz,
            'xyz_offsets': xyz_offsets,
            'scales': gs_scales,
            'scales_canon': gs_scales_canon,
            'rotq': deformed_gs_rotq,
            'rotq_canon': gs_rotq,
            'rotmat': deformed_gs_rotmat,
            'rotmat_canon': gs_rotmat,
            'shs': deformed_gs_shs,
            'opacity': gs_opacity,
            'normals': deformed_normals,
            'normals_canon': canon_normals,
            'active_sh_degree': self.active_sh_degree,
            'rot6d_canon': gs_rot6d,
            'lbs_weights': lbs_weights,
            'posedirs': posedirs,
            'gt_lbs_weights': gt_lbs_weights,
        }

    def oneupSHdegree(self):
        if self.active_sh_degree < self.max_sh_degree:
            logger.info(f"Going from SH degree {self.active_sh_degree} to {self.active_sh_degree + 1}")
            self.active_sh_degree += 1

    @torch.no_grad()
    def get_vitruvian_verts(self):
        vitruvian_pose = torch.zeros(69, dtype=self.smpl.dtype, device=self.device)
        vitruvian_pose[2] = 1.0
        vitruvian_pose[5] = -1.0
        smpl_output = self.smpl(body_pose=vitruvian_pose[None], betas=self.betas[None], disable_posedirs=False)
        vitruvian_verts = smpl_output.vertices[0]
        self.A_t2vitruvian = smpl_output.A[0].detach()
        self.T_t2vitruvian = smpl_output.T[0].detach()
        self.inv_T_t2vitruvian = torch.inverse(self.T_t2vitruvian)
        self.inv_A_t2vitruvian = torch.inverse(self.A_t2vitruvian)
        self.canonical_offsets = smpl_output.shape_offsets + smpl_output.pose_offsets
        self.canonical_offsets = self.canonical_offsets[0].detach()
        self.vitruvian_verts = vitruvian_verts.detach()
        return vitruvian_verts.detach()
    
    @torch.no_grad()
    def get_vitruvian_verts_template(self):
        
        vitruvian_pose = torch.zeros(69, dtype=self.smpl_template.dtype, device=self.device)
        vitruvian_pose[2] = 1.0
        vitruvian_pose[5] = -1.0
        smpl_output = self.smpl_template(body_pose=vitruvian_pose[None], betas=self.betas[None], disable_posedirs=False)
        vitruvian_verts = smpl_output.vertices[0]
        return vitruvian_verts.detach()
    
    def train(self):
        pass
    
    def eval(self):
        pass
    
    def initialize(self):
        # 1ï¸âƒ£ é¡¶ç‚¹ä½ç½®åˆå§‹åŒ–
        # è·å– SMPL æ¨¡æ¿ä¸‹ Vitruvian poseï¼ˆå³â€œæ ‡å‡†å§¿æ€â€ï¼‰å¯¹åº”çš„æ‰€æœ‰é¡¶ç‚¹ä½ç½®ï¼Œä½œä¸ºé«˜æ–¯åˆå§‹ä¸­å¿ƒã€‚
        t_pose_verts = self.get_vitruvian_verts_template()

        # åˆå§‹åŒ–æ¯ä¸ªé«˜æ–¯ç‚¹çš„å°ºåº¦å€ç‡ï¼ˆå¯å­¦ä¹ é¡¹ï¼‰
        self.scaling_multiplier = torch.ones((t_pose_verts.shape[0], 1), device="cuda")

        # åˆå§‹åŒ–åç§»ä¸º 0ï¼Œæ„å‘³ç€åˆå§‹ä½ç½®å°±æ˜¯ SMPL Vitruvian æ¨¡æ¿çš„é¡¶ç‚¹ä½ç½®
        xyz_offsets = torch.zeros_like(t_pose_verts)
        # åˆå§‹åŒ–é¢œè‰²ï¼Œ æ‰€æœ‰é«˜æ–¯ç‚¹é¢œè‰²åˆå§‹åŒ–ä¸ºç°è‰² (0.5, 0.5, 0.5)
        colors = torch.ones_like(t_pose_verts) * 0.5

        # åˆå§‹åŒ– spherical harmonicsï¼ˆSHï¼‰ç³»æ•°ï¼Œç»´åº¦ä¸º [num_points, 16, 3]
            # ä»…ç¬¬ 0 é˜¶ï¼ˆå¸¸æ•°é¡¹ï¼‰ä¸ºéé›¶ï¼Œè®¾ç½®ä¸ºç°è‰²
        shs = torch.zeros((colors.shape[0], 3, 16)).float().cuda()
        shs[:, :3, 0 ] = colors
        shs[:, 3:, 1:] = 0.0
        shs = shs.transpose(1, 2).contiguous()

        # åˆå§‹åŒ–æ¯ä¸ªé«˜æ–¯ç‚¹çš„ 3D å°ºåº¦ä¸º 0ï¼ˆå°†åœ¨ä¸‹æ–¹è®¡ç®—ï¼‰
        scales = torch.zeros_like(t_pose_verts)

        
        for v in range(t_pose_verts.shape[0]):
            # æŸ¥æ‰¾ä¸å½“å‰é¡¶ç‚¹ v ç›¸è¿çš„æ‰€æœ‰è¾¹
            selected_edges = torch.any(self.edges == v, dim=-1)
            # è®¡ç®—æ‰€æœ‰ç›¸è¿è¾¹çš„é•¿åº¦ï¼ˆç”¨äºä¼°ç®—å±€éƒ¨å‡ ä½•å¤§å°ï¼‰
            selected_edges_len = torch.norm(
                t_pose_verts[self.edges[selected_edges][0]] - t_pose_verts[self.edges[selected_edges][1]], 
                dim=-1
            )
            # ç¼©æ”¾è¾¹é•¿ï¼Œç”¨äºæ§åˆ¶åˆå§‹åŒ–å°ºåº¦å¤§å°ï¼ˆé»˜è®¤ init_scale_multiplier=0.5ï¼‰
            selected_edges_len *= self.init_scale_multiplier

            # è®¾ç½®é«˜æ–¯åœ¨ X å’Œ Y æ–¹å‘çš„å°ºåº¦ï¼Œåˆå§‹å–æœ€å¤§è¾¹é•¿ï¼Œå¹¶å–å¯¹æ•°ï¼ˆå› ä¸ºåç»­ä¼š exp å›å»ï¼‰
            scales[v, 0] = torch.log(torch.max(selected_edges_len))
            scales[v, 1] = torch.log(torch.max(selected_edges_len))
            
            if not self.use_surface:
                scales[v, 2] = torch.log(torch.max(selected_edges_len))
        
        if self.use_surface or self.init_2d:
            scales = scales[..., :2]
            
        scales = torch.exp(scales)
        
        if self.use_surface or self.init_2d:
            scale_z = torch.ones_like(scales[:, -1:]) * SCALE_Z
            scales = torch.cat([scales, scale_z], dim=-1)

        import trimesh
        # âœ… æ„å»º trimesh ç½‘æ ¼å¯¹è±¡ï¼Œç”¨ SMPL æ¨¡æ¿çš„ T-pose é¡¶ç‚¹å’Œé¢æ„å»ºç½‘æ ¼ï¼Œç”¨äºè®¡ç®—æ¯ä¸ªé¡¶ç‚¹çš„è¡¨é¢æ³•å‘ã€‚
            # t_pose_verts: å½“å‰å¸§ SMPL æ¨¡æ¿ä¸‹çš„é¡¶ç‚¹åæ ‡ï¼ˆTensorï¼‰ã€‚
        mesh = trimesh.Trimesh(vertices=t_pose_verts.detach().cpu().numpy(), faces=self.smpl_template.faces)

        # âœ… è·å–æ¯ä¸ªé¡¶ç‚¹çš„å•ä½æ³•å‘å‘é‡ï¼Œå¹¶è½¬ä¸º CUDA tensorï¼Œä»¥ä¾¿åç»­åœ¨ GPU ä¸Šä¸é«˜æ–¯é»˜è®¤æ³•å‘å¯¹é½ã€‚
        vert_normals = torch.tensor(mesh.vertex_normals).float().cuda()

        # âœ… æ„é€ æ‰€æœ‰é«˜æ–¯çš„é»˜è®¤åˆå§‹æ³•å‘å‘é‡ï¼Œå…¨è®¾ä¸º [0, 0, 1]ï¼ˆZè½´æœä¸Šï¼‰ï¼Œå³å‡è®¾åˆå§‹é«˜æ–¯æ˜¯å‚ç›´æœä¸Šçš„æ¤­çƒä½“ã€‚
        gs_normals = torch.zeros_like(vert_normals)
        gs_normals[:, 2] = 1.0

        # âœ… è®¡ç®—ä»é»˜è®¤æ³•å‘ gs_normals åˆ°çœŸå®è¡¨é¢æ³•å‘ vert_normals çš„æ—‹è½¬çŸ©é˜µï¼ˆæ¯ä¸ªé«˜æ–¯ä¸€ä¸ª3Ã—3çŸ©é˜µï¼‰ã€‚
        # ç”¨äºå°†é«˜æ–¯ä»â€œæœä¸Šâ€å§¿æ€æ—‹è½¬å¯¹é½åˆ°ç½‘æ ¼çœŸå®æ³•å‘ã€‚
        norm_rotmat = torch_rotation_matrix_from_vectors(gs_normals, vert_normals)

        # âœ… å°†æ—‹è½¬çŸ©é˜µè½¬æ¢ä¸ºï¼š
        #     rotq: å››å…ƒæ•°è¡¨ç¤ºï¼ˆç”¨äºæ’å€¼ç­‰ä»»åŠ¡ï¼‰
        
        #     rot6d: 6D æ—‹è½¬è¡¨ç¤ºï¼ˆé¿å…æ¬§æ‹‰è§’/Gimbalé”é—®é¢˜ï¼Œé€‚åˆç½‘ç»œå­¦ä¹ ï¼‰
        rotq = matrix_to_quaternion(norm_rotmat)
        rot6d = matrix_to_rotation_6d(norm_rotmat)

        # âœ… å­˜å‚¨åŸå§‹é»˜è®¤æ³•å‘ï¼ˆZè½´ï¼‰ä¸ºç±»æˆå‘˜ï¼Œåç»­å¯ç”¨äºå¯¹æ¯”å’Œæ—‹è½¬ã€‚
        self.normals = gs_normals

        # âœ… å°†é»˜è®¤æ³•å‘é€šè¿‡æ—‹è½¬çŸ©é˜µ norm_rotmat å˜æ¢ä¸ºå¯¹é½åçš„æ³•å‘ï¼Œç»“æœå³ä¸ºæ¯ä¸ªé«˜æ–¯ç‚¹åœ¨åˆå§‹ä½ç½®ä¸‹çš„çœŸå®æ³•å‘ã€‚
        deformed_normals = (norm_rotmat @ gs_normals.unsqueeze(-1)).squeeze(-1)

        # âœ… åˆå§‹åŒ–æ¯ä¸ªé«˜æ–¯ç‚¹çš„ä¸é€æ˜åº¦ï¼ˆé€æ˜åº¦ï¼‰ä¸ºå¸¸æ•° 0.1ï¼Œåç»­è®­ç»ƒä¸­å¯è°ƒã€‚
        opacity = 0.1 * torch.ones((t_pose_verts.shape[0], 1), dtype=torch.float, device="cuda")

        # âœ… è·å– SMPL æ¨¡æ¿ä¸­ï¼š
        #     posedirs: æ¯ä¸ªé¡¶ç‚¹åœ¨å…³èŠ‚æ—‹è½¬æ—¶çš„å½¢å˜æ–¹å‘ï¼ˆç”¨äº LBS æ’å€¼ï¼‰
        #     lbs_weights: æ¯ä¸ªé¡¶ç‚¹çš„ LBS æƒé‡ï¼ˆå¯¹åº”éª¨éª¼çš„å½±å“æƒé‡ï¼‰
        #     ç”¨äºé«˜æ–¯å½¢å˜æ—¶é©±åŠ¨æ¯ä¸ªé«˜æ–¯ç‚¹çš„è¿åŠ¨ã€‚
        posedirs = self.smpl_template.posedirs.detach().clone()
        lbs_weights = self.smpl_template.lbs_weights.detach().clone()

        # âœ… è®¾ç½®å½“å‰é«˜æ–¯ç‚¹çš„æ•°é‡ä¸º SMPL æ¨¡æ¿é¡¶ç‚¹æ•°ã€‚
        self.n_gs = t_pose_verts.shape[0]

        # âœ… è®¾ç½®é«˜æ–¯ä¸­å¿ƒä¸º SMPL Vitruvian pose çš„é¡¶ç‚¹åæ ‡ï¼Œå¹¶å¯ç”¨æ¢¯åº¦æ›´æ–°ï¼Œç”¨äºåç»­ä¼˜åŒ–ã€‚
        self._xyz = nn.Parameter(t_pose_verts.requires_grad_(True))

         # âœ… åˆå§‹åŒ–æ¯ä¸ªé«˜æ–¯ç‚¹åœ¨è§†å›¾ç©ºé—´ä¸­çš„æœ€å¤§æŠ•å½±åŠå¾„ä¸º0ï¼ˆç”¨äºè§†é”¥è£å‰ªç­‰æ¸²æŸ“åŠ é€Ÿç­–ç•¥ï¼‰ï¼Œåç»­æ¸²æŸ“ä¸­ä¼šæ›´æ–°è¯¥å€¼ã€‚
        self.max_radii2D = torch.zeros((self.get_xyz.shape[0]), device="cuda")
        return {
            'xyz_offsets': xyz_offsets,
            'scales': scales,
            'rot6d_canon': rot6d,
            'shs': shs,
            'opacity': opacity,
            'lbs_weights': lbs_weights,
            'posedirs': posedirs,
            'deformed_normals': deformed_normals,
            'faces': self.smpl.faces_tensor,
            'edges': self.edges,
        }

    def setup_optimizer(self, cfg):
        self.percent_dense = cfg.percent_dense
        self.xyz_gradient_accum = torch.zeros((self.get_xyz.shape[0], 1), device="cuda")
        self.denom = torch.zeros((self.get_xyz.shape[0], 1), device="cuda")
        self.spatial_lr_scale = cfg.smpl_spatial
        
        params = [
            {'params': [self._xyz], 'lr': cfg.position_init * cfg.smpl_spatial, "name": "xyz"},
            {'params': self.triplane.parameters(), 'lr': cfg.vembed, 'name': 'v_embed'},
            {'params': self.geometry_dec.parameters(), 'lr': cfg.geometry, 'name': 'geometry_dec'},
            {'params': self.appearance_dec.parameters(), 'lr': cfg.appearance, 'name': 'appearance_dec'},
            {'params': self.deformation_dec.parameters(), 'lr': cfg.deformation, 'name': 'deform_dec'},
        ]
        
        if hasattr(self, 'global_orient') and self.global_orient.requires_grad:
            params.append({'params': self.global_orient, 'lr': cfg.smpl_pose, 'name': 'global_orient'})
        
        if hasattr(self, 'body_pose') and self.body_pose.requires_grad:
            params.append({'params': self.body_pose, 'lr': cfg.smpl_pose, 'name': 'body_pose'})
            
        if hasattr(self, 'betas') and self.betas.requires_grad:
            params.append({'params': self.betas, 'lr': cfg.smpl_betas, 'name': 'betas'})
            
        if hasattr(self, 'transl') and self.betas.requires_grad:
            params.append({'params': self.transl, 'lr': cfg.smpl_trans, 'name': 'transl'})
        
        self.non_densify_params_keys = [
            'global_orient', 'body_pose', 'betas', 'transl', 
            'v_embed', 'geometry_dec', 'appearance_dec', 'deform_dec',
        ]
        
        for param in params:
            logger.info(f"Parameter: {param['name']}, lr: {param['lr']}")

        self.optimizer = torch.optim.Adam(params, lr=0.0, eps=1e-15)
        self.xyz_scheduler_args = get_expon_lr_func(
            lr_init=cfg.position_init  * cfg.smpl_spatial,
            lr_final=cfg.position_final  * cfg.smpl_spatial,
            lr_delay_mult=cfg.position_delay_mult,
            max_steps=cfg.position_max_steps,
        )

    def update_learning_rate(self, iteration):
        ''' Learning rate scheduling per step '''
        for param_group in self.optimizer.param_groups:
            if param_group["name"] == "xyz":
                lr = self.xyz_scheduler_args(iteration)
                param_group['lr'] = lr
                return lr


    def replace_tensor_to_optimizer(self, tensor, name):
        optimizable_tensors = {}
        for group in self.optimizer.param_groups:
            if group["name"] == name:
                stored_state = self.optimizer.state.get(group['params'][0], None)
                stored_state["exp_avg"] = torch.zeros_like(tensor)
                stored_state["exp_avg_sq"] = torch.zeros_like(tensor)

                del self.optimizer.state[group['params'][0]]
                group["params"][0] = nn.Parameter(tensor.requires_grad_(True))
                self.optimizer.state[group['params'][0]] = stored_state

                optimizable_tensors[group["name"]] = group["params"][0]
        return optimizable_tensors

    def _prune_optimizer(self, mask):
        optimizable_tensors = {}
        for group in self.optimizer.param_groups:
            if group["name"] in self.non_densify_params_keys:
                continue
            stored_state = self.optimizer.state.get(group['params'][0], None)
            if stored_state is not None:
                stored_state["exp_avg"] = stored_state["exp_avg"][mask]
                stored_state["exp_avg_sq"] = stored_state["exp_avg_sq"][mask]

                del self.optimizer.state[group['params'][0]]
                group["params"][0] = nn.Parameter((group["params"][0][mask].requires_grad_(True)))
                self.optimizer.state[group['params'][0]] = stored_state

                optimizable_tensors[group["name"]] = group["params"][0]
            else:
                group["params"][0] = nn.Parameter(group["params"][0][mask].requires_grad_(True))
                optimizable_tensors[group["name"]] = group["params"][0]
        return optimizable_tensors

    def prune_points(self, mask):
        valid_points_mask = ~mask
        optimizable_tensors = self._prune_optimizer(valid_points_mask)

        self._xyz = optimizable_tensors["xyz"]
        self.scaling_multiplier = self.scaling_multiplier[valid_points_mask]
        
        self.scales_tmp = self.scales_tmp[valid_points_mask]
        self.opacity_tmp = self.opacity_tmp[valid_points_mask]
        self.rotmat_tmp = self.rotmat_tmp[valid_points_mask]
        
        self.xyz_gradient_accum = self.xyz_gradient_accum[valid_points_mask]

        self.denom = self.denom[valid_points_mask]
        self.max_radii2D = self.max_radii2D[valid_points_mask]

    def cat_tensors_to_optimizer(self, tensors_dict):
        optimizable_tensors = {}
        for group in self.optimizer.param_groups:
            if group["name"] in self.non_densify_params_keys:
                continue
            
            assert len(group["params"]) == 1
            extension_tensor = tensors_dict[group["name"]]
            stored_state = self.optimizer.state.get(group['params'][0], None)
            if stored_state is not None:

                stored_state["exp_avg"] = torch.cat((stored_state["exp_avg"], torch.zeros_like(extension_tensor)), dim=0)
                stored_state["exp_avg_sq"] = torch.cat((stored_state["exp_avg_sq"], torch.zeros_like(extension_tensor)), dim=0)

                del self.optimizer.state[group['params'][0]]
                group["params"][0] = nn.Parameter(torch.cat((group["params"][0], extension_tensor), dim=0).requires_grad_(True))
                self.optimizer.state[group['params'][0]] = stored_state

                optimizable_tensors[group["name"]] = group["params"][0]
            else:
                group["params"][0] = nn.Parameter(torch.cat((group["params"][0], extension_tensor), dim=0).requires_grad_(True))
                optimizable_tensors[group["name"]] = group["params"][0]

        return optimizable_tensors

    def densification_postfix(self, new_xyz, new_scaling_multiplier, new_opacity_tmp, new_scales_tmp, new_rotmat_tmp):
        d = {
            "xyz": new_xyz,
        }

        optimizable_tensors = self.cat_tensors_to_optimizer(d)
        self._xyz = optimizable_tensors["xyz"]
        self.scaling_multiplier = torch.cat((self.scaling_multiplier, new_scaling_multiplier), dim=0)
        self.opacity_tmp = torch.cat([self.opacity_tmp, new_opacity_tmp], dim=0)
        self.scales_tmp = torch.cat([self.scales_tmp, new_scales_tmp], dim=0)
        self.rotmat_tmp = torch.cat([self.rotmat_tmp, new_rotmat_tmp], dim=0)
        
        self.xyz_gradient_accum = torch.zeros((self.get_xyz.shape[0], 1), device="cuda")
        self.denom = torch.zeros((self.get_xyz.shape[0], 1), device="cuda")
        self.max_radii2D = torch.zeros((self.get_xyz.shape[0]), device="cuda")

    def densify_and_split(self, grads, grad_threshold, scene_extent, N=2):
        n_init_points = self.get_xyz.shape[0]
        scales = self.scales_tmp
        rotation = self.rotmat_tmp
        # Extract points that satisfy the gradient condition
        padded_grad = torch.zeros((n_init_points), device="cuda")
        padded_grad[:grads.shape[0]] = grads.squeeze()
        selected_pts_mask = torch.where(padded_grad >= grad_threshold, True, False)
        selected_pts_mask = torch.logical_and(selected_pts_mask,
                                              torch.max(scales, dim=1).values > self.percent_dense*scene_extent)
        # filter elongated gaussians
        med = scales.median(dim=1, keepdim=True).values 
        stdmed_mask = (((scales - med) / med).squeeze(-1) >= 1.0).any(dim=-1)
        selected_pts_mask = torch.logical_and(selected_pts_mask, stdmed_mask)
        
        stds = scales[selected_pts_mask].repeat(N,1)
        means = torch.zeros((stds.size(0), 3),device="cuda")
        samples = torch.normal(mean=means, std=torch.relu(stds))
        rots = rotation[selected_pts_mask].repeat(N,1,1)
        new_xyz = torch.bmm(rots, samples.unsqueeze(-1)).squeeze(-1) + self.get_xyz[selected_pts_mask].repeat(N, 1)
        new_scaling_multiplier = self.scaling_multiplier[selected_pts_mask].repeat(N,1) / (0.8*N)
        new_opacity_tmp = self.opacity_tmp[selected_pts_mask].repeat(N,1)
        new_scales_tmp = self.scales_tmp[selected_pts_mask].repeat(N,1)
        new_rotmat_tmp = self.rotmat_tmp[selected_pts_mask].repeat(N,1,1)
        
        self.densification_postfix(new_xyz, new_scaling_multiplier, new_opacity_tmp, new_scales_tmp, new_rotmat_tmp)

        prune_filter = torch.cat((selected_pts_mask, torch.zeros(N * selected_pts_mask.sum(), device="cuda", dtype=bool)))
        self.prune_points(prune_filter)

    def densify_and_clone(self, grads, grad_threshold, scene_extent):
        # Extract points that satisfy the gradient condition
        scales = self.scales_tmp
        grad_cond = torch.norm(grads, dim=-1) >= grad_threshold
        scale_cond = torch.max(scales, dim=1).values <= self.percent_dense*scene_extent
        
        selected_pts_mask = torch.where(grad_cond, True, False)
        selected_pts_mask = torch.logical_and(selected_pts_mask, scale_cond)
        
        new_xyz = self._xyz[selected_pts_mask]
        new_scaling_multiplier = self.scaling_multiplier[selected_pts_mask]
        new_opacity_tmp = self.opacity_tmp[selected_pts_mask]
        new_scales_tmp = self.scales_tmp[selected_pts_mask]
        new_rotmat_tmp = self.rotmat_tmp[selected_pts_mask]
        
        self.densification_postfix(new_xyz, new_scaling_multiplier, new_opacity_tmp, new_scales_tmp, new_rotmat_tmp)

    def densify_and_prune(self, human_gs_out, max_grad, min_opacity, extent, max_screen_size, max_n_gs=None):
        grads = self.xyz_gradient_accum / self.denom
        grads[grads.isnan()] = 0.0
        
        self.opacity_tmp = human_gs_out['opacity']
        self.scales_tmp = human_gs_out['scales_canon']
        self.rotmat_tmp = human_gs_out['rotmat_canon']
        
        max_n_gs = max_n_gs if max_n_gs else self.get_xyz.shape[0] + 1
        
        if self.get_xyz.shape[0] <= max_n_gs:
            self.densify_and_clone(grads, max_grad, extent)
            self.densify_and_split(grads, max_grad, extent)

        prune_mask = (self.opacity_tmp < min_opacity).squeeze()
        if max_screen_size:
            big_points_vs = self.max_radii2D > max_screen_size
            big_points_ws = self.scales_tmp.max(dim=1).values > 0.1 * extent
            prune_mask = torch.logical_or(torch.logical_or(prune_mask, big_points_vs), big_points_ws)
        self.prune_points(prune_mask)
        self.n_gs = self.get_xyz.shape[0]
        torch.cuda.empty_cache()

    def add_densification_stats(self, viewspace_point_tensor, update_filter):
        self.xyz_gradient_accum[update_filter] += torch.norm(viewspace_point_tensor.grad[:update_filter.shape[0]][update_filter,:2], dim=-1, keepdim=True)
        self.denom[update_filter] += 1
        
